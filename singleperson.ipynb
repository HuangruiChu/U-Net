{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个文件进行二分割（background与target），相比前一个版本，做出以下优化与调整：\n",
    "\n",
    "1.先padding把图片变成正方形。再resize。\n",
    "\n",
    "2.Loss选取Dice，IoU，MSE，BCE，Dice+BCE。\n",
    "\n",
    "3.UNet最后一层是sigmoid。\n",
    "\n",
    "可以拓展的方向：把不同loss_function的图整合在一张图中，可参考CXM的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本的引入\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义Earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改编版！新增monitor(mIoU)\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, monitor=\"val_acc\", patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            monitor (string): 可以选 \"val_acc\"or \"val_loss\"or\"val_mIoU\"\n",
    "                            \n",
    "                            Default: \"val_acc\"\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.monitor=monitor\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.val_acc_max = 0\n",
    "        self.val_mIoU_max = 0\n",
    "        self.delta = delta\n",
    "    \n",
    "    def __call__(self, val, model):\n",
    "        if self.monitor=='val_loss':\n",
    "            val_loss=val\n",
    "            score = -val_loss\n",
    "\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model)\n",
    "                self.counter = 0\n",
    "        elif self.monitor=='val_acc':\n",
    "            #这里的val是0-100之间的数。\n",
    "            val_acc=val\n",
    "            score = val_acc\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_acc, model)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_acc, model)\n",
    "                self.counter = 0   \n",
    "        elif self.monitor=='val_mIoU':\n",
    "            #这里的val是0-100之间的数。\n",
    "            val_mIoU=val\n",
    "            score = val_mIoU\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_mIoU, model)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_mIoU, model)\n",
    "                self.counter = 0 \n",
    "    def save_checkpoint(self, val, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        '''Saves model when validation accuracy increase.'''\n",
    "        if self.monitor=='val_loss':\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val:.6f}).  Saving model ...')           \n",
    "            self.val_loss_min = val\n",
    "        if self.monitor=='val_acc':\n",
    "            if self.verbose:\n",
    "                print(f'Validation accuracy increased ({self.val_acc_max:.6f}% --> {val:.6f}%).  Saving model ...')\n",
    "            self.val_acc_max = val\n",
    "        if self.monitor=='val_mIoU':\n",
    "            if self.verbose:\n",
    "                print(f'Validation mIoU increased ({self.val_mIoU_max:.6f} --> {val:.6f}).  Saving model ...')\n",
    "            self.val_mIoU_max = val\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\t# 这里会存储迄今最优模型的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片的预处理：\n",
    "\n",
    "## 1. 先padding成正方形，再resize。\n",
    "\n",
    "## 2.为了符合二分类，把label所有非0数字全改为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_pic(image,mask):\n",
    "    #first, get the length and the width of the image and mask(image 和 mask的长宽是一致的)\n",
    "    length=image.size[0]\n",
    "    width=image.size[1]\n",
    "    if length>width:\n",
    "        image = T.Pad((0, (length-width)//2),fill=0, padding_mode=\"constant\")(image)\n",
    "        mask = T.Pad((0, (length-width)//2),fill=0, padding_mode=\"constant\")(mask)\n",
    "    elif length<width:\n",
    "        image = T.Pad(((width-length)//2,0),fill=0, padding_mode=\"constant\")(image)\n",
    "        mask = T.Pad(((width-length)//2,0),fill=0, padding_mode=\"constant\")(mask)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#为了可以同时处理image和mask，设置了一下的函数\n",
    "def my_transform1(image, mask):\n",
    "    image,mask=padding_pic(image,mask)\n",
    "    #my_transform1是针对训练集的，可以做到data augmentation的效果\n",
    "    if random.random() > 0.5:\n",
    "        image = tf.hflip(image)\n",
    "        mask = tf.hflip(mask)\n",
    "    if random.random() > 0.5:\n",
    "        image = tf.vflip(image)\n",
    "        mask = tf.vflip(mask)\n",
    "    #对image进行resize，totensor，还有normalize\n",
    "    transform_image = T.Compose([   \n",
    "        T.Resize([256,256]),        \n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    image = transform_image(image)\n",
    "    #对mask进行resize，把它转换成array，把所有大于1的地方换成1，最后转成tensor。\n",
    "    mask=T.functional.resize(mask,(256,256))\n",
    "    mask=np.array(mask)\n",
    "    mask=(mask>=1).astype(int)\n",
    "    mask = torch.from_numpy(mask) \n",
    "    return image, mask\n",
    "    \n",
    "def my_transform2(image, mask):\n",
    "    image,mask=padding_pic(image,mask)\n",
    "    #my_transform2是针对valid&test的，所以就不需要rotation之类的处理了。\n",
    "    #对image进行resize，totensor，还有normalize\n",
    "    transform_image = T.Compose([\n",
    "        T.Resize([256, 256]),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    image = transform_image(image)\n",
    "    #对mask进行resize，把它转换成array，把所有大于1的地方换成1，最后转成tensor。\n",
    "    mask=T.functional.resize(mask,(256,256))\n",
    "    mask=np.array(mask)\n",
    "    mask=(mask>=1).astype(int)\n",
    "    mask = torch.from_numpy(mask) \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_path=None, mask_path=None, transform=None,data=\"train\"):   \n",
    "        \"\"\"\n",
    "        初始化自定义Dataset类的参数\n",
    "        Attributes\n",
    "            file_path: 字符串，数据集的存储路径，例如‘./UCF101/train’ 或 './UCF101/eval'等\n",
    "            mask_path: 字符串，数据集的存储路径，例如‘./UCF101/train_annotation’等\n",
    "            transform: 传入一个从torchvision.transforms定义的数据预处理\n",
    "        \"\"\"\n",
    "        self.count=0\n",
    "        self.transform = transform\n",
    "        if data=='train':\n",
    "            self.name=open(os.path.join(\"../input/singleperson/TrainVal_images\",\"train_id.txt\"))\n",
    "        elif data==\"valid\":\n",
    "            self.name=open(os.path.join(\"../input/singleperson/TrainVal_images\",\"val_id.txt\"))\n",
    "        elif data==\"test\":\n",
    "            self.name=open(os.path.join(\"../input/singleperson/TrainVal_images\",\"val_id.txt\"))\n",
    "        # 初始化给定文件夹下的所有数据\n",
    "        self.init_all_data(file_path,mask_path,data) \n",
    "\n",
    "        return None\n",
    "        \n",
    "\n",
    "    def init_all_data(self,file_path,mask_path,data):\n",
    "        \"\"\"\n",
    "        初始化该数据集内所有的图像及其对应的标签，保存在self.images和self.labels两个列表内\n",
    "        Attributes\n",
    "            file_path: 字符串，数据集文件夹的存储路径\n",
    "            mask_path: 字符串，数据集文件夹的存储路径\n",
    "        \"\"\"\n",
    "        # 初始化两个列表，记录该数据集内每一张图片的完整路径及其对应的mask\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for name in self.name:\n",
    "            # 得当当前图片的完整路径，若是有效图片，则记录该图片\n",
    "            self.count+=1\n",
    "            if data==\"train\"and self.count<=2000:\n",
    "                img = os.path.join(file_path,name[0:-1]+\".jpg\")\n",
    "                mask = os.path.join(mask_path,name[0:-1]+\".png\")\n",
    "                if self.is_valid_image(img) and self.is_valid_image(mask):\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(mask)\n",
    "            if data==\"valid\" and self.count<=600:\n",
    "                img = os.path.join(file_path,name[0:-1]+\".jpg\")\n",
    "                mask = os.path.join(mask_path,name[0:-1]+\".png\")\n",
    "                if self.is_valid_image(img) and self.is_valid_image(mask):\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(mask)\n",
    "            elif data==\"test\" and self.count>=5000:\n",
    "                img = os.path.join(file_path,name[0:-1]+\".jpg\")\n",
    "                mask = os.path.join(mask_path,name[0:-1]+\".png\")\n",
    "                if self.is_valid_image(img) and self.is_valid_image(mask):\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(mask)\n",
    "        return None\n",
    "\n",
    "        \n",
    "    def is_valid_image(self, img_path):\n",
    "        \"\"\"\n",
    "        判断图片是否为可以打开的有效文件\n",
    "        Attributes\n",
    "            img_path: 字符串，待检测图片的存储路径\n",
    "        Returns\n",
    "            valid: 布尔变量，True/False分别表示该图片是否可以正常打开\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 若读取成功，设valid为True\n",
    "            i = Image.open(img_path)\n",
    "            valid = True\n",
    "        except:\n",
    "            # 若读取失败，设valid为False\n",
    "            valid = False\n",
    "            \n",
    "        return valid\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        按给定索引，获取对应的图片及其标签\n",
    "        Attributes\n",
    "            idx: int类型数字，表示目标图像的索引\n",
    "        Returns\n",
    "            image: 一个打开的PIL.Image对象，是PIL库存储图像的一种数据格式（类似于OpenCV利用numpy张量存储图像）\n",
    "            label: Image类型，表示对应的mask\n",
    "        \"\"\"\n",
    "        # 利用PIL.Image.open打开图片，并将其强制转化为RGB格式（防止数据集中混杂灰度图，导致读取出单通道图片，送入网络因矩阵维度不一致而报错）\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        # 获取对应的mask\n",
    "        label = Image.open(self.labels[idx])\n",
    "        \n",
    "        # 进行预处理的变换\n",
    "        if self.transform:\n",
    "            image,label = self.transform(image,label)\n",
    "        return image, label\n",
    "   \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        获取数据集中图像的总数，该方法的作用是用于DataLoader去调用，从而获取在给定Batch Size的情况下，一个Epoch的总长，\n",
    "        从而可以在一个Epoch结束时实现shuffle数据集的功能\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设立dataset和dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(\"../input/singleperson/TrainVal_images/TrainVal_images/train_images\",\n",
    "                       \"../input/singleperson/TrainVal_parsing_annotations/TrainVal_parsing_annotations/TrainVal_parsing_annotations/train_segmentations\",\n",
    "                       transform=my_transform1,\n",
    "                      data=\"train\")\n",
    "valid_data=MyDataset(\"../input/singleperson/TrainVal_images/TrainVal_images/val_images\",\n",
    "                       \"../input/singleperson/TrainVal_parsing_annotations/TrainVal_parsing_annotations/TrainVal_parsing_annotations/val_segmentations\",\n",
    "                       transform=my_transform2,\n",
    "                      data=\"valid\")\n",
    "test_data=MyDataset(\"../input/singleperson/TrainVal_images/TrainVal_images/val_images\",\n",
    "                       \"../input/singleperson/TrainVal_parsing_annotations/TrainVal_parsing_annotations/TrainVal_parsing_annotations/val_segmentations\",\n",
    "                       transform=my_transform2,\n",
    "                      data=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_workers=2\n",
    "train_loader=data.DataLoader(dataset=train_data,batch_size=32,\n",
    "                             shuffle=True, num_workers=Num_workers)\n",
    "valid_loader=data.DataLoader(dataset=valid_data,batch_size=32,\n",
    "                             shuffle=True, num_workers=Num_workers)\n",
    "test_loader=Data.DataLoader(dataset=test_data,batch_size=32,\n",
    "                             shuffle=True, num_workers=Num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net，输出层为sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 1. 根据网络层的不同定义不同的初始化方式     \n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        #nn.init.constant_(m.bias, 0) bias不要全初始化为0\n",
    "        nn.init.normal_(m.bias, mean=0, std=1)\n",
    "    # 也可以判断是否为conv2d，使用相应的初始化方式 \n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "     # 是否为批归一化层\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "#使用这样的初始化后，模型的初始表现确实好了些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算IoU的functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据IoUloss代码改编"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(inputs,targets,smooth=1):\n",
    "    #把inputs，targets转成cpu再detach，这样就不会占用GPU资源。\n",
    "    inputs = inputs.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().view(-1)\n",
    "    #要对input进行threshold，让他变成（0，1）组成的。\n",
    "    inputs=torch.tensor((inputs>0.5).astype(np.int32)).view(-1)\n",
    "    #intersection is equivalent to True Positive count\n",
    "    #union is the mutually inclusive area of all labels & predictions \n",
    "    intersection = (inputs * targets).sum()\n",
    "    total = (inputs + targets).sum()\n",
    "    union = total - intersection \n",
    "    IoU = (intersection + smooth)/(union + smooth)\n",
    "    return IoU.numpy()\n",
    "#return是numpy这样占的内存就不会过大了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新增mIoU(其实用的是IoU)如果要改成mIoU只要把里面的两处给改了。\n",
    "def train_model(model,device, patience, n_epochs):\n",
    "    \n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    # to track the training mIoU as the model trains\n",
    "    train_mIoU = []\n",
    "    # to track the valid mIoU as the model trains\n",
    "    valid_mIoU = []\n",
    "    # to track the average training mIoU per epoch as the model trains \n",
    "    avg_train_mIoU = []\n",
    "    # to track the average validation mIoU per epoch as the model trains\n",
    "    avg_valid_mIoU = [] \n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(\"val_mIoU\",patience=patience, verbose=True,delta=0)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    " \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        \n",
    "        for step, (X, y) in enumerate(train_loader):\n",
    "            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the loss\n",
    "            loss = loss_func(output, y)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss and training mIoU\n",
    "            train_losses.append(loss.item())\n",
    "            train_mIoU.append(IoU(output, y)) \n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "     \n",
    "        for step, (X, y) in enumerate(valid_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the loss\n",
    "            loss = loss_func(output, y)\n",
    "            # record validation loss and valid mIoU\n",
    "            valid_losses.append(loss.item())\n",
    "            valid_mIoU.append(IoU(output, y)) \n",
    "            \n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        train_mIoU= np.average( train_mIoU)\n",
    "        valid_mIoU= np.average( valid_mIoU)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        avg_train_mIoU.append(train_mIoU)\n",
    "        avg_valid_mIoU.append(valid_mIoU)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'train_mIoU: {train_mIoU:.5f} ' +\n",
    "                     f'\\n    valid_loss: {valid_loss:.5f} ' +\n",
    "                     f'valid_mIoU: {valid_mIoU:.5f} ' )\n",
    "        \n",
    "        print(print_msg)\n",
    "        # early_stopping needs the validation acc to check if it has incresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_mIoU, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        train_mIoU = []\n",
    "        valid_mIoU = []\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    " \n",
    "    return  model, avg_train_losses, avg_valid_losses,avg_train_mIoU,avg_valid_mIoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# create a new model with these weights\n",
    "model = UNet(in_channels=3, out_channels=1, init_features=32).to(device)\n",
    "model.apply(weight_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = torch.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "class IoULoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = torch.sigmoid(inputs)    \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #intersection is equivalent to True Positive count\n",
    "        #union is the mutually inclusive area of all labels & predictions \n",
    "        intersection = (inputs * targets).sum()\n",
    "        total = (inputs + targets).sum()\n",
    "        union = total - intersection \n",
    "        \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "                \n",
    "        return 1 - IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice_BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = torch.sigmoid(inputs)    \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-5)\n",
    "#loss_func = torch.nn.MSELoss()  \n",
    "#loss_func = torch.nn.BCELoss()  \n",
    "#loss_func = DiceLoss()\n",
    "loss_func = IoULoss()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=50\n",
    "patience = 7\n",
    "#optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-4)\n",
    "model, train_loss, valid_loss,train_mIoU,valid_mIoU = train_model(model ,device, patience, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化单个图片的训练结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印一下图片，ground truth 和我做出的mask\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "plt.figure(dpi = 600)#让图片清晰些\n",
    "#导入要验证的图片\n",
    "image,label=valid_data.__getitem__(170)\n",
    "#打印原图\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(np.transpose(image.numpy(),(1,2,0)))\n",
    "plt.axis('off')#不显示坐标轴\n",
    "#打印ground truth\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"ground truth\")\n",
    "plt.imshow(label.numpy())\n",
    "plt.axis('off')#不显示坐标轴\n",
    "#打印我做出来的mask\n",
    "img = torch.unsqueeze(image,dim=0)\n",
    "b_x=img.cuda()\n",
    "out=model(b_x).to(torch.float64)\n",
    "out=torch.max(out,1)[1]\n",
    "out=out.cpu().detach().numpy()[0]\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"output mask\")\n",
    "plt.imshow(out1)\n",
    "plt.axis('off')#不显示坐标轴\n",
    "\n",
    "#保存图片\n",
    "plt.axis('off')#不显示坐标轴\n",
    "plt.savefig('valid_170.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化loss和mIoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "minposs = valid_loss.index(min(valid_loss))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "#plt.ylim(0, 0.5) # consistent scale\n",
    "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('Dice_loss.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the mIoU as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_mIoU)+1),train_mIoU, label='Training mIoU')\n",
    "plt.plot(range(1,len(valid_mIoU)+1),valid_mIoU,label='Validation mIoU')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "maxposs = valid_mIoU.index(max(valid_mIoU))+1 \n",
    "plt.axvline(maxposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('mIoU')\n",
    "#plt.ylim(0, 0.5) # consistent scale\n",
    "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('Dice_mIoU.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader,loss_func):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    test_mIoU=[]\n",
    "    for (X, y) in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(X)\n",
    "        # calculate the loss\n",
    "        loss = loss_func(output, y)\n",
    "        # record validation loss\n",
    "        test_loss.append(loss.item())\n",
    "        test_mIoU.append(IoU(output,y))   \n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Average mIoU: {:.4f}'.format(\n",
    "        np.average(test_loss),np.average(test_mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, device, test_loader,loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化test部分的model表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印一下图片，ground truth 和我做出的mask\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "plt.figure(dpi = 600)#让图片清晰些\n",
    "#导入要验证的图片\n",
    "image,label=test_data.__getitem__(170)\n",
    "#打印原图\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(np.transpose(image.numpy(),(1,2,0)))\n",
    "plt.axis('off')#不显示坐标轴\n",
    "#打印ground truth\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"ground truth\")\n",
    "plt.imshow(label.numpy())\n",
    "plt.axis('off')#不显示坐标轴\n",
    "#打印我做出来的mask\n",
    "img = torch.unsqueeze(image,dim=0)\n",
    "b_x=img.cuda()\n",
    "out=model(b_x).to(torch.float64)\n",
    "out=torch.max(out,1)[1]\n",
    "out=out.cpu().detach().numpy()[0]\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"output mask\")\n",
    "plt.imshow(out1)\n",
    "plt.axis('off')#不显示坐标轴\n",
    "\n",
    "#保存图片\n",
    "plt.axis('off')#不显示坐标轴\n",
    "plt.savefig('valid_170.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把多张训练结果的图片一起可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageshow(num_figure,model,data=\"train\"):\n",
    "    if data==\"train\":\n",
    "        dataloader=train_data\n",
    "    elif data==\"valid\":\n",
    "        dataloader=valid_data\n",
    "    elif data==\"test\":\n",
    "        dataloader=test_data\n",
    "    #定义了一个打印多张图片的function\n",
    "    fig, axes = plt.subplots(num_figure, 4,dpi = 600, figsize=(7, 6))\n",
    "    imgs=np.arange(num_figure)*10\n",
    "    for i in imgs:\n",
    "        #导入要验证的图片\n",
    "        image,label=dataloader.__getitem__(i)\n",
    "        i=int(i/10)#设置index\n",
    "        #打印原图\n",
    "        axes[i][0].imshow(np.transpose(image.numpy(),(1,2,0)))\n",
    "        #打印ground truth\n",
    "        axes[i][1].imshow(label.numpy())\n",
    "        #打印我做出来的mask\n",
    "        img = torch.unsqueeze(image,dim=0)\n",
    "        b_x=img.cuda()\n",
    "        out=model(b_x).to(torch.float64)\n",
    "        out=torch.max(out,1)[1]\n",
    "        out=out.cpu().detach().numpy()[0]\n",
    "        axes[i][2].imshow(out)\n",
    "    for ax in axes.ravel():\n",
    "        ax.axis('off')#关掉坐标轴       \n",
    "    fig.tight_layout() #让图片紧密 \n",
    "    #设置标签\n",
    "    axes[0][0].set_title(\"Original image\")\n",
    "    axes[0][1].set_title(\"Ground truth\")\n",
    "    axes[0][2].set_title(\"Output mask\")\n",
    "    #保存图片\n",
    "    fig.savefig('{}_imshow.png'.format(data))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageshow(6,model,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageshow(6,model,\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageshow(6,model,\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
