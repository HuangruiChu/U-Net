{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个文件进行多类分割，相比前一个版本，做出以下优化与调整：\n",
    "\n",
    "1.先padding把图片变成正方形。再resize。\n",
    "\n",
    "2.Loss选取CrossEntropyLoss。\n",
    "\n",
    "3.UNet最后一层是conv2d。\n",
    "\n",
    "4.数据集是Lip的multi—person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本的引入\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as T\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义Earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改编版！新增monitor(mIoU)\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, monitor=\"val_acc\", patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            monitor (string): 可以选 \"val_acc\"or \"val_loss\"or\"val_mIoU\"\n",
    "                            \n",
    "                            Default: \"val_acc\"\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.monitor=monitor\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.val_acc_max = 0\n",
    "        self.val_mIoU_max = 0\n",
    "        self.delta = delta\n",
    "    \n",
    "    def __call__(self, val, model):\n",
    "        if self.monitor=='val_loss':\n",
    "            val_loss=val\n",
    "            score = -val_loss\n",
    "\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_loss, model)\n",
    "                self.counter = 0\n",
    "        elif self.monitor=='val_acc':\n",
    "            #这里的val是0-100之间的数。\n",
    "            val_acc=val\n",
    "            score = val_acc\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_acc, model)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_acc, model)\n",
    "                self.counter = 0   \n",
    "        elif self.monitor=='val_mIoU':\n",
    "            #这里的val是0-100之间的数。\n",
    "            val_mIoU=val\n",
    "            score = val_mIoU\n",
    "            if self.best_score is None:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_mIoU, model)\n",
    "            elif score < self.best_score + self.delta:\n",
    "                self.counter += 1\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "            else:\n",
    "                self.best_score = score\n",
    "                self.save_checkpoint(val_mIoU, model)\n",
    "                self.counter = 0 \n",
    "    def save_checkpoint(self, val, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        '''Saves model when validation accuracy increase.'''\n",
    "        if self.monitor=='val_loss':\n",
    "            if self.verbose:\n",
    "                print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val:.6f}).  Saving model ...')           \n",
    "            self.val_loss_min = val\n",
    "        if self.monitor=='val_acc':\n",
    "            if self.verbose:\n",
    "                print(f'Validation accuracy increased ({self.val_acc_max:.6f}% --> {val:.6f}%).  Saving model ...')\n",
    "            self.val_acc_max = val\n",
    "        if self.monitor=='val_mIoU':\n",
    "            if self.verbose:\n",
    "                print(f'Validation mIoU increased ({self.val_mIoU_max:.6f} --> {val:.6f}).  Saving model ...')\n",
    "            self.val_mIoU_max = val\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\t# 这里会存储迄今最优模型的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图片的预处理：\n",
    "\n",
    "## 1. 先padding成正方形，再resize。\n",
    "\n",
    "## 2.为了符合 CrossEntropyLoss的输入要求，在对mask预处理完后把其数据格式转变成long。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_pic(image,mask):\n",
    "    #first, get the length and the width of the image and mask(image 和 mask的长宽是一致的)\n",
    "    length=image.size[0]\n",
    "    width=image.size[1]\n",
    "    if length>width:\n",
    "        image = T.Pad((0, (length-width)//2),fill=0, padding_mode=\"constant\")(image)\n",
    "        mask = T.Pad((0, (length-width)//2),fill=0, padding_mode=\"constant\")(mask)\n",
    "    elif length<width:\n",
    "        image = T.Pad(((width-length)//2,0),fill=0, padding_mode=\"constant\")(image)\n",
    "        mask = T.Pad(((width-length)//2,0),fill=0, padding_mode=\"constant\")(mask)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#为了可以同时处理image和mask，设置了一下的函数\n",
    "def my_transform1(image, mask):\n",
    "    image,mask=padding_pic(image,mask)\n",
    "    #my_transform1是针对训练集的，可以做到data augmentation的效果,flip version\n",
    "    if random.random() > 0.5:\n",
    "        image = tf.hflip(image)\n",
    "        mask = tf.hflip(mask)\n",
    "    if random.random() > 0.5:\n",
    "        image = tf.vflip(image)\n",
    "        mask = tf.vflip(mask)\n",
    "    #对image进行resize，totensor，还有normalize\n",
    "    transform_image = T.Compose([   \n",
    "        T.Resize([256,256]),        \n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    image = transform_image(image)\n",
    "    #对mask进行resize，最后转成tensor。\n",
    "    mask=T.functional.resize(mask,(256,256))\n",
    "    mask=np.array(mask, dtype='int64')\n",
    "    mask = torch.from_numpy(mask) \n",
    "    mask=torch.squeeze(mask).long()#选用了CrossELoss就要这样转换\n",
    "    return image, mask\n",
    "    \n",
    "def my_transform2(image, mask):\n",
    "    #my_transform2是针对valid&test的，所以就不需要rotation之类的处理了。\n",
    "    image,mask=padding_pic(image,mask)\n",
    "    #对image进行resize，totensor，还有normalize\n",
    "    transform_image = T.Compose([\n",
    "        T.Resize([256, 256]),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    image = transform_image(image)\n",
    "    #对mask进行resize，最后转成tensor。\n",
    "    mask=T.functional.resize(mask,(256,256))\n",
    "    mask=np.array(mask, dtype='int64')\n",
    "    mask = torch.from_numpy(mask) \n",
    "    mask=torch.squeeze(mask).long()#选用了CrossELoss就要这样转换\n",
    "    return image, mask\n",
    "def my_transform3(image, mask):\n",
    "    #my_transform1是针对训练集的，可以做到data augmentation的效果,rotation version\n",
    "    image,mask=padding_pic(image,mask)\n",
    "    # 拿到角度的随机数。angle是一个-180到180之间的一个数\n",
    "    angle = T.RandomRotation.get_params([-180, 180])\n",
    "    # 对image和mask做相同的旋转操作，保证他们都旋转angle角度\n",
    "    mask=tf.rotate(mask,angle)\n",
    "    image=tf.rotate(image,angle)\n",
    "#     image.mask=random_resize_crop(image,mask,400,256)\n",
    "    #对image进行resize，totensor，还有normalize\n",
    "    transform_image = T.Compose([   \n",
    "        T.Resize([256,256]),        \n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean= [0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    image = transform_image(image)\n",
    "    #对mask进行resize，然后转成tensor。\n",
    "    mask=T.functional.resize(mask,(256,256))\n",
    "    mask=np.array(mask, dtype='int64')\n",
    "    mask = torch.from_numpy(mask) \n",
    "    mask=torch.squeeze(mask).long()#选用了CrossELoss就要这样转换\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, file_path=None, mask_path=None, transform=None,data=\"train\"):   \n",
    "        \"\"\"\n",
    "        初始化自定义Dataset类的参数\n",
    "        Attributes\n",
    "            file_path: 字符串，数据集的存储路径，例如‘./UCF101/train’ 或 './UCF101/eval'等\n",
    "            mask_path: 字符串，数据集的存储路径，例如‘./UCF101/train_annotation’等\n",
    "            transform: 传入一个从torchvision.transforms定义的数据预处理\n",
    "        \"\"\"\n",
    "        self.count=0\n",
    "        self.transform = transform\n",
    "        if data=='train':\n",
    "            self.name=open(os.path.join(\"../input/multiperson/instance-level_human_parsing/Training\",\"train_id.txt\"))\n",
    "        elif data==\"valid\":\n",
    "            self.name=open(os.path.join(\"../input/multiperson/instance-level_human_parsing/Validation\",\"val_id.txt\"))\n",
    "            #我要改变一下，就是这里的val_id会被分出去一些,就是10000的一半！\n",
    "        elif data==\"test\":\n",
    "            self.name=open(os.path.join(\"../input/multiperson/instance-level_human_parsing/Validation\",\"val_id.txt\"))\n",
    "        # 初始化给定文件夹下的所有数据\n",
    "        self.init_all_data(file_path,mask_path,data) \n",
    "\n",
    "        return None\n",
    "        \n",
    "\n",
    "    def init_all_data(self,file_path,mask_path,data):\n",
    "        \"\"\"\n",
    "        初始化该数据集内所有的图像及其对应的标签，保存在self.images和self.labels两个列表内\n",
    "        Attributes\n",
    "            file_path: 字符串，数据集文件夹的存储路径\n",
    "            mask_path: 字符串，数据集文件夹的存储路径\n",
    "        \"\"\"\n",
    "        # 初始化两个列表，记录该数据集内每一张图片的完整路径及其对应的mask\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        for name in self.name:\n",
    "            # 得当当前图片的完整路径，若是有效图片，则记录该图片\n",
    "            self.count+=1\n",
    "            if data==\"train\"and self.count<=5000:\n",
    "                img = os.path.join(file_path,name[0:-1]+\".jpg\")\n",
    "                mask = os.path.join(mask_path,name[0:-1]+\".png\")\n",
    "                if self.is_valid_image(img) and self.is_valid_image(mask):\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(mask)\n",
    "            if data==\"valid\" and self.count<=1200:\n",
    "                img = os.path.join(file_path,name[0:-1]+\".jpg\")\n",
    "                mask = os.path.join(mask_path,name[0:-1]+\".png\")\n",
    "                if self.is_valid_image(img) and self.is_valid_image(mask):\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(mask)\n",
    "            elif data==\"test\" and self.count>=3000:\n",
    "                img = os.path.join(file_path,name[0:-1]+\".jpg\")\n",
    "                mask = os.path.join(mask_path,name[0:-1]+\".png\")\n",
    "                if self.is_valid_image(img) and self.is_valid_image(mask):\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(mask)\n",
    "        return None\n",
    "\n",
    "        \n",
    "    def is_valid_image(self, img_path):\n",
    "        \"\"\"\n",
    "        判断图片是否为可以打开的有效文件\n",
    "        Attributes\n",
    "            img_path: 字符串，待检测图片的存储路径\n",
    "        Returns\n",
    "            valid: 布尔变量，True/False分别表示该图片是否可以正常打开\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 若读取成功，设valid为True\n",
    "            i = Image.open(img_path)\n",
    "            valid = True\n",
    "        except:\n",
    "            # 若读取失败，设valid为False\n",
    "            valid = False\n",
    "            \n",
    "        return valid\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        按给定索引，获取对应的图片及其标签\n",
    "        Attributes\n",
    "            idx: int类型数字，表示目标图像的索引\n",
    "        Returns\n",
    "            image: 一个打开的PIL.Image对象，是PIL库存储图像的一种数据格式（类似于OpenCV利用numpy张量存储图像）\n",
    "            label: Image类型，表示对应的mask\n",
    "        \"\"\"\n",
    "        # 利用PIL.Image.open打开图片，并将其强制转化为RGB格式（防止数据集中混杂灰度图，导致读取出单通道图片，送入网络因矩阵维度不一致而报错）\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        # 获取对应的mask\n",
    "        label = Image.open(self.labels[idx])\n",
    "        #获取mask后就要把它转换成全0，1的array，再换成Image\n",
    "        \n",
    "        # 进行预处理的变换\n",
    "        if self.transform:\n",
    "            image,label = self.transform(image,label)\n",
    "        return image, label\n",
    "   \n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        获取数据集中图像的总数，该方法的作用是用于DataLoader去调用，从而获取在给定Batch Size的情况下，一个Epoch的总长，\n",
    "        从而可以在一个Epoch结束时实现shuffle数据集的功能\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设立dataset和dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(\"../input/multiperson/instance-level_human_parsing/Training/Images\",\n",
    "                       \"../input/multiperson/instance-level_human_parsing/Training/Category_ids\",\n",
    "                       transform=my_transform2,\n",
    "                      data=\"train\")\n",
    "valid_data=MyDataset(\"../input/multiperson/instance-level_human_parsing/Validation/Images\",\n",
    "                       \"../input/multiperson/instance-level_human_parsing/Validation/Category_ids\",\n",
    "                       transform=my_transform2,\n",
    "                      data=\"valid\")\n",
    "test_data=MyDataset(\"../input/multiperson/instance-level_human_parsing/Validation/Images\",\n",
    "                       \"../input/multiperson/instance-level_human_parsing/Validation/Category_ids\",\n",
    "                       transform=my_transform2,\n",
    "                      data=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_workers=2\n",
    "train_loader=data.DataLoader(dataset=train_data,batch_size=32,\n",
    "                             shuffle=True, num_workers=Num_workers)\n",
    "valid_loader=data.DataLoader(dataset=valid_data,batch_size=32,\n",
    "                             shuffle=True, num_workers=Num_workers)\n",
    "test_loader=Data.DataLoader(dataset=test_data,batch_size=32,\n",
    "                             shuffle=True, num_workers=Num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核心model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net，输出层为conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return self.conv(dec1)\n",
    "\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res+Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # resnet = torchvision.models.resnet.resnet50(pretrained=True)\n",
    "\n",
    "\n",
    "# class ConvBlock(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Helper module that consists of a Conv -> BN -> ReLU\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
    "#         super().__init__()\n",
    "#         self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
    "#         self.bn = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.with_nonlinearity = with_nonlinearity\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = self.bn(x)\n",
    "#         if self.with_nonlinearity:\n",
    "#             x = self.relu(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class Bridge(nn.Module):\n",
    "#     \"\"\"\n",
    "#     This is the middle layer of the UNet which just consists of some\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "#         self.bridge = nn.Sequential(\n",
    "#             ConvBlock(in_channels, out_channels),\n",
    "#             ConvBlock(out_channels, out_channels)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.bridge(x)\n",
    "\n",
    "\n",
    "# class UpBlockForUNetWithResNet50(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
    "#                  upsampling_method=\"conv_transpose\"):\n",
    "#         super().__init__()\n",
    "\n",
    "#         if up_conv_in_channels == None:\n",
    "#             up_conv_in_channels = in_channels\n",
    "#         if up_conv_out_channels == None:\n",
    "#             up_conv_out_channels = out_channels\n",
    "\n",
    "#         if upsampling_method == \"conv_transpose\":\n",
    "#             self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
    "#         elif upsampling_method == \"bilinear\":\n",
    "#             self.upsample = nn.Sequential(\n",
    "#                 nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "#                 nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "#             )\n",
    "#         self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
    "#         self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
    "\n",
    "#     def forward(self, up_x, down_x):\n",
    "#         \"\"\"\n",
    "#         :param up_x: this is the output from the previous up block\n",
    "#         :param down_x: this is the output from the down block\n",
    "#         :return: upsampled feature map\n",
    "#         \"\"\"\n",
    "#         x = self.upsample(up_x)\n",
    "#         x = torch.cat([x, down_x], 1)\n",
    "#         x = self.conv_block_1(x)\n",
    "#         x = self.conv_block_2(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class UNetWithResnet50Encoder(nn.Module):\n",
    "#     DEPTH = 6\n",
    "\n",
    "#     def __init__(self, n_classes=2):\n",
    "#         super().__init__()\n",
    "#         resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "#         down_blocks = []\n",
    "#         up_blocks = []\n",
    "#         self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
    "#         self.input_pool = list(resnet.children())[3]\n",
    "#         for bottleneck in list(resnet.children()):\n",
    "#             if isinstance(bottleneck, nn.Sequential):\n",
    "#                 down_blocks.append(bottleneck)\n",
    "#         self.down_blocks = nn.ModuleList(down_blocks)\n",
    "#         self.bridge = Bridge(2048, 2048)\n",
    "#         up_blocks.append(UpBlockForUNetWithResNet50(2048, 1024))\n",
    "#         up_blocks.append(UpBlockForUNetWithResNet50(1024, 512))\n",
    "#         up_blocks.append(UpBlockForUNetWithResNet50(512, 256))\n",
    "#         up_blocks.append(UpBlockForUNetWithResNet50(in_channels=128 + 64, out_channels=128,\n",
    "#                                                     up_conv_in_channels=256, up_conv_out_channels=128))\n",
    "#         up_blocks.append(UpBlockForUNetWithResNet50(in_channels=64 + 3, out_channels=64,\n",
    "#                                                     up_conv_in_channels=128, up_conv_out_channels=64))\n",
    "\n",
    "#         self.up_blocks = nn.ModuleList(up_blocks)\n",
    "\n",
    "#         self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n",
    "\n",
    "#     def forward(self, x, with_output_feature_map=False):\n",
    "#         pre_pools = dict()\n",
    "#         pre_pools[f\"layer_0\"] = x\n",
    "#         x = self.input_block(x)\n",
    "#         pre_pools[f\"layer_1\"] = x\n",
    "#         x = self.input_pool(x)\n",
    "\n",
    "#         for i, block in enumerate(self.down_blocks, 2):\n",
    "#             x = block(x)\n",
    "#             if i == (UNetWithResnet50Encoder.DEPTH - 1):\n",
    "#                 continue\n",
    "#             pre_pools[f\"layer_{i}\"] = x\n",
    "\n",
    "#         x = self.bridge(x)\n",
    "\n",
    "#         for i, block in enumerate(self.up_blocks, 1):\n",
    "#             key = f\"layer_{UNetWithResnet50Encoder.DEPTH - 1 - i}\"\n",
    "#             x = block(x, pre_pools[key])\n",
    "#         output_feature_map = x\n",
    "#         x = self.out(x)\n",
    "#         del pre_pools\n",
    "#         if with_output_feature_map:\n",
    "#             return x, output_feature_map\n",
    "#         else:\n",
    "#             return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=False)\n",
    "\n",
    "# def convrelu(in_channels, out_channels, kernel, padding):\n",
    "#     return nn.Sequential(\n",
    "#         nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "#         nn.ReLU(inplace=True),\n",
    "#     )\n",
    "\n",
    "# class ResNetUNet(nn.Module):\n",
    "\n",
    "#     def __init__(self, n_class):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.base_model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "        \n",
    "#         self.base_layers = list(base_model.children())                \n",
    "        \n",
    "#         self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "#         self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "#         self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)        \n",
    "#         self.layer1_1x1 = convrelu(64, 64, 1, 0)       \n",
    "#         self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)        \n",
    "#         self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "#         self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)        \n",
    "#         self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "#         self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "#         self.layer4_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "#         self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "#         self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "#         self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "#         self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "#         self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "#         self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "#         self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "#         self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "#         self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "#     def forward(self, input):\n",
    "#         x_original = self.conv_original_size0(input)\n",
    "#         x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "#         layer0 = self.layer0(input)            \n",
    "#         layer1 = self.layer1(layer0)\n",
    "#         layer2 = self.layer2(layer1)\n",
    "#         layer3 = self.layer3(layer2)        \n",
    "#         layer4 = self.layer4(layer3)\n",
    "        \n",
    "#         layer4 = self.layer4_1x1(layer4)\n",
    "#         x = self.upsample(layer4)\n",
    "#         layer3 = self.layer3_1x1(layer3)\n",
    "#         x = torch.cat([x, layer3], dim=1)\n",
    "#         x = self.conv_up3(x)\n",
    " \n",
    "#         x = self.upsample(x)\n",
    "#         layer2 = self.layer2_1x1(layer2)\n",
    "#         x = torch.cat([x, layer2], dim=1)\n",
    "#         x = self.conv_up2(x)\n",
    "\n",
    "#         x = self.upsample(x)\n",
    "#         layer1 = self.layer1_1x1(layer1)\n",
    "#         x = torch.cat([x, layer1], dim=1)\n",
    "#         x = self.conv_up1(x)\n",
    "\n",
    "#         x = self.upsample(x)\n",
    "#         layer0 = self.layer0_1x1(layer0)\n",
    "#         x = torch.cat([x, layer0], dim=1)\n",
    "#         x = self.conv_up0(x)\n",
    "        \n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, x_original], dim=1)\n",
    "#         x = self.conv_original_size2(x)        \n",
    "        \n",
    "#         out = self.conv_last(x)        \n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet++(需改进）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "# class VGGBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, middle_channels, out_channels, act_func=nn.ReLU(inplace=True)):\n",
    "#         super(VGGBlock, self).__init__()\n",
    "#         self.act_func = act_func\n",
    "#         self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "#         self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.act_func(out)\n",
    "#\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "#         out = self.act_func(out)\n",
    "#         return out\n",
    "\n",
    "class NestedUNet(nn.Module):\n",
    "    def __init__(self, args,in_channel,out_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.args_deepsupervision  = args\n",
    "\n",
    "        nb_filter = [16,32, 64, 128, 256]\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = DoubleConv(in_channel, nb_filter[0])\n",
    "        self.conv1_0 = DoubleConv(nb_filter[0], nb_filter[1])\n",
    "        self.conv2_0 = DoubleConv(nb_filter[1], nb_filter[2])\n",
    "        self.conv3_0 = DoubleConv(nb_filter[2], nb_filter[3])\n",
    "        self.conv4_0 = DoubleConv(nb_filter[3], nb_filter[4])\n",
    "\n",
    "        self.conv0_1 = DoubleConv(nb_filter[0]+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_1 = DoubleConv(nb_filter[1]+nb_filter[2], nb_filter[1])\n",
    "        self.conv2_1 = DoubleConv(nb_filter[2]+nb_filter[3], nb_filter[2])\n",
    "        self.conv3_1 = DoubleConv(nb_filter[3]+nb_filter[4], nb_filter[3])\n",
    "\n",
    "        self.conv0_2 = DoubleConv(nb_filter[0]*2+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_2 = DoubleConv(nb_filter[1]*2+nb_filter[2], nb_filter[1])\n",
    "        self.conv2_2 = DoubleConv(nb_filter[2]*2+nb_filter[3], nb_filter[2])\n",
    "\n",
    "        self.conv0_3 = DoubleConv(nb_filter[0]*3+nb_filter[1], nb_filter[0])\n",
    "        self.conv1_3 = DoubleConv(nb_filter[1]*3+nb_filter[2], nb_filter[1])\n",
    "\n",
    "        self.conv0_4 = DoubleConv(nb_filter[0]*4+nb_filter[1], nb_filter[0])\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        if self.args_deepsupervision:\n",
    "            self.final1 = nn.Conv2d(nb_filter[0], out_channel, kernel_size=1)\n",
    "            self.final2 = nn.Conv2d(nb_filter[0], out_channel, kernel_size=1)\n",
    "            self.final3 = nn.Conv2d(nb_filter[0], out_channel, kernel_size=1)\n",
    "            self.final4 = nn.Conv2d(nb_filter[0], out_channel, kernel_size=1)\n",
    "        else:\n",
    "            self.final = nn.Conv2d(nb_filter[0], out_channel, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "\n",
    "        if self.args_deepsupervision:\n",
    "            output1 = self.final1(x0_1)\n",
    "            output1 = self.sigmoid(output1)\n",
    "            output2 = self.final2(x0_2)\n",
    "            output2 = self.sigmoid(output2)\n",
    "            output3 = self.final3(x0_3)\n",
    "            output3 = self.sigmoid(output3)\n",
    "            output4 = self.final4(x0_4)\n",
    "            output4 = self.sigmoid(output4)\n",
    "            return [output1, output2, output3, output4]\n",
    "\n",
    "        else:\n",
    "            output = self.final(x0_4)\n",
    "            output = self.sigmoid(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 1. 根据网络层的不同定义不同的初始化方式     \n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        #nn.init.constant_(m.bias, 0) bias不要全初始化为0\n",
    "        nn.init.normal_(m.bias, mean=0, std=1)\n",
    "    # 也可以判断是否为conv2d，使用相应的初始化方式 \n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "     # 是否为批归一化层\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "#使用这样的初始化后，模型的初始表现确实好了些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算IoU的functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在计算mIoU前，先把输入的数据softmax成one-hot。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#忽略ground的计算mIoU的方式\n",
    "def IoU(inputs,targets,n_classes=20,smooth=1):\n",
    "    #先把input softmax一下\n",
    "    inputs=torch.softmax(inputs,dim=1)\n",
    "    #把inputs，targets转成cpu再detach，这样就不会占用GPU资源。\n",
    "    inputs = inputs.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().view(-1)\n",
    "    ious=[]\n",
    "    for i in range(1,n_classes):  # This goes from 1:n_classes-1 -> class \"0\" is ignored\n",
    "        pred=inputs[:,i,:,:]\n",
    "        pred=torch.tensor(pred).view(-1)\n",
    "        target=targets==i\n",
    "        #intersection is equivalent to True Positive count\n",
    "        #union is the mutually inclusive area of all labels & predictions \n",
    "        intersection = (pred * target).sum()\n",
    "        total = (pred + target).sum()\n",
    "        union = total - intersection \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "        ious.append(IoU)\n",
    "    return np.mean(ious)\n",
    "#return是numpy这样占的内存就不会过大了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把ground也计入mIoU\n",
    "def IoU(inputs,targets,n_classes=20,smooth=1):\n",
    "    #先把input softmax一下\n",
    "    inputs=torch.softmax(inputs,dim=1)\n",
    "    #把inputs，targets转成cpu再detach，这样就不会占用GPU资源。\n",
    "    inputs = inputs.cpu().detach().numpy()\n",
    "    targets = targets.cpu().detach().view(-1)\n",
    "    ious=[]\n",
    "    for i in range(0,n_classes):  \n",
    "        pred=inputs[:,i,:,:]\n",
    "        pred=torch.tensor(pred).view(-1)\n",
    "        target=targets==i\n",
    "        #intersection is equivalent to True Positive count\n",
    "        #union is the mutually inclusive area of all labels & predictions \n",
    "        intersection = (pred * target).sum()\n",
    "        total = (pred + target).sum()\n",
    "        union = total - intersection \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "        ious.append(IoU)\n",
    "    #print(ious)   \n",
    "    return np.mean(ious)\n",
    "#return是numpy这样占的内存就不会过大了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新增mIoU(其实用的是IoU)如果要改成mIoU只要把里面的两处给改了。\n",
    "def train_model(model,device, patience, n_epochs):\n",
    "    \n",
    "    # to track the training loss as the model trains\n",
    "    train_losses = []\n",
    "    # to track the validation loss as the model trains\n",
    "    valid_losses = []\n",
    "    # to track the average training loss per epoch as the model trains\n",
    "    avg_train_losses = []\n",
    "    # to track the average validation loss per epoch as the model trains\n",
    "    avg_valid_losses = [] \n",
    "    # to track the training mIoU as the model trains\n",
    "    train_mIoU = []\n",
    "    # to track the valid mIoU as the model trains\n",
    "    valid_mIoU = []\n",
    "    # to track the average training mIoU per epoch as the model trains \n",
    "    avg_train_mIoU = []\n",
    "    # to track the average validation mIoU per epoch as the model trains\n",
    "    avg_valid_mIoU = [] \n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(\"val_mIoU\",patience=patience, verbose=True,delta=0)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    " \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train() # prep model for training\n",
    "        \n",
    "        for step, (X, y) in enumerate(train_loader):\n",
    "            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the loss\n",
    "            loss = loss_func(output, y)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # record training loss and training mIoU\n",
    "            train_losses.append(loss.item())\n",
    "            train_mIoU.append(IoU(output, y)) \n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval() # prep model for evaluation\n",
    "     \n",
    "        for step, (X, y) in enumerate(valid_loader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(X)\n",
    "            # calculate the loss\n",
    "            loss = loss_func(output, y)\n",
    "            # record validation loss and valid mIoU\n",
    "            valid_losses.append(loss.item())\n",
    "            valid_mIoU.append(IoU(output, y)) \n",
    "            \n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        train_mIoU= np.average( train_mIoU)\n",
    "        valid_mIoU= np.average( valid_mIoU)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        avg_train_mIoU.append(train_mIoU)\n",
    "        avg_valid_mIoU.append(valid_mIoU)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'train_mIoU: {train_mIoU:.5f} ' +\n",
    "                     f'\\n    valid_loss: {valid_loss:.5f} ' +\n",
    "                     f'valid_mIoU: {valid_mIoU:.5f} ' )\n",
    "        \n",
    "        print(print_msg)\n",
    "        # early_stopping needs the validation acc to check if it has incresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_mIoU, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        train_mIoU = []\n",
    "        valid_mIoU = []\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    print(\"Done!\")\n",
    "    return  model, avg_train_losses, avg_valid_losses,avg_train_mIoU,avg_valid_mIoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# create a new model with these weights\n",
    "model = UNet(in_channels=3, out_channels=20, init_features=32).to(device)\n",
    "model.apply(weight_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-5)\n",
    "#loss_func = torch.nn.MSELoss()  \n",
    "loss_func = torch.nn.CrossEntropyLoss()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=50\n",
    "patience = 7\n",
    "#optimizer=torch.optim.Adam(model.parameters(),lr=lr,weight_decay=1e-4)\n",
    "model, train_loss, valid_loss,train_mIoU,valid_mIoU = train_model(model ,device, patience, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化单个图片的训练结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印一下图片，ground truth 和我做出的mask\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "plt.figure(dpi = 600)#让图片清晰些\n",
    "#导入要验证的图片\n",
    "image,label=valid_data.__getitem__(170)\n",
    "#打印原图\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(np.transpose(image.numpy(),(1,2,0)))\n",
    "plt.axis('off')#不显示坐标轴\n",
    "#打印ground truth\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"ground truth\")\n",
    "plt.imshow(label.numpy())\n",
    "plt.axis('off')#不显示坐标轴\n",
    "#打印我做出来的mask\n",
    "img = torch.unsqueeze(image,dim=0)\n",
    "b_x=img.cuda()\n",
    "out=model(b_x).to(torch.float64)\n",
    "out=torch.max(out,1)[1]\n",
    "out=out.cpu().detach().numpy()[0]\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"output mask\")\n",
    "plt.imshow(out1)\n",
    "plt.axis('off')#不显示坐标轴\n",
    "\n",
    "#保存图片\n",
    "plt.axis('off')#不显示坐标轴\n",
    "plt.savefig('valid_170.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化loss和mIoU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
    "plt.xlabel('epochs',fontsize=30)\n",
    "plt.ylabel('loss',fontsize=30)\n",
    "#plt.ylim(0, 0.5) # consistent scale\n",
    "plt.xlim(1, len(train_loss)+1) # consistent scale\n",
    "plt.yticks(fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'best',fontsize=30)\n",
    "plt.tight_layout()\n",
    "fig.savefig('Unet_100_loss.png', bbox_inches='tight',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the mIoU as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_mIoU)+1),train_mIoU, label='Training mIoU')\n",
    "plt.plot(range(1,len(valid_mIoU)+1),valid_mIoU,label='Validation mIoU')\n",
    "# find position of lowest validation loss\n",
    "maxposs = valid_mIoU.index(max(valid_mIoU))+1 \n",
    "plt.axvline(maxposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs',fontsize=30)\n",
    "plt.ylabel('mIoU',fontsize=30)\n",
    "#plt.ylim(0, 0.5) # consistent scale\n",
    "plt.xlim(1, len(train_loss)+1) # consistent scale\n",
    "plt.yticks(fontsize=30)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.grid(True)\n",
    "plt.legend(loc = 'best',fontsize=30)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('Unet256_100mIoU.png', bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader,loss_func):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    test_mIoU=[]\n",
    "    for (X, y) in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(X)\n",
    "        # calculate the loss\n",
    "        loss = loss_func(output, y)\n",
    "        # record validation loss\n",
    "        test_loss.append(loss.item())\n",
    "        test_mIoU.append(IoU(output,y))   \n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Average mIoU: {:.4f}'.format(\n",
    "        np.average(test_loss),np.average(test_mIoU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, device, test_loader,loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化test部分的model表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印一下图片，ground truth 和我做出的mask\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "plt.figure(dpi = 600)#让图片清晰些\n",
    "#导入要验证的图片\n",
    "image,label=test_data.__getitem__(170)\n",
    "#打印原图\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"image\")\n",
    "plt.imshow(np.transpose(image.numpy(),(1,2,0)))\n",
    "plt.axis('off')#不显示坐标轴\n",
    "#打印ground truth\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"ground truth\")\n",
    "plt.imshow(label.numpy())\n",
    "plt.axis('off')#不显示坐标轴\n",
    "#打印我做出来的mask\n",
    "img = torch.unsqueeze(image,dim=0)\n",
    "b_x=img.cuda()\n",
    "out=model(b_x).to(torch.float64)\n",
    "out=torch.max(out,1)[1]\n",
    "out=out.cpu().detach().numpy()[0]\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"output mask\")\n",
    "plt.imshow(out1)\n",
    "plt.axis('off')#不显示坐标轴\n",
    "\n",
    "#保存图片\n",
    "plt.axis('off')#不显示坐标轴\n",
    "plt.savefig('valid_170.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把多张训练结果的图片一起可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageshow(num_figure,model,data=\"train\"):\n",
    "    if data==\"train\":\n",
    "        dataloader=train_data\n",
    "    elif data==\"valid\":\n",
    "        dataloader=valid_data\n",
    "    elif data==\"test\":\n",
    "        dataloader=test_data\n",
    "    #定义了一个打印多张图片的function\n",
    "    fig, axes = plt.subplots(num_figure, 4,dpi = 600, figsize=(7, 6))\n",
    "    imgs=np.arange(num_figure)*10\n",
    "    for i in imgs:\n",
    "        #导入要验证的图片\n",
    "        image,label=dataloader.__getitem__(i)\n",
    "        i=int(i/10)#设置index\n",
    "        #打印原图\n",
    "        axes[i][0].imshow(np.transpose(image.numpy(),(1,2,0)))\n",
    "        #打印ground truth\n",
    "        axes[i][1].imshow(label.numpy())\n",
    "        #打印我做出来的mask\n",
    "        img = torch.unsqueeze(image,dim=0)\n",
    "        b_x=img.cuda()\n",
    "        out=model(b_x).to(torch.float64)\n",
    "        out=torch.max(out,1)[1]\n",
    "        out=out.cpu().detach().numpy()[0]\n",
    "        axes[i][2].imshow(out)\n",
    "    for ax in axes.ravel():\n",
    "        ax.axis('off')#关掉坐标轴       \n",
    "    #设置标签\n",
    "    axes[0][0].set_title(\"Original image\")\n",
    "    axes[0][1].set_title(\"Ground truth\")\n",
    "    axes[0][2].set_title(\"Output mask\")\n",
    "    #保存图片\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('{}_imshow.png'.format(data),pad_inches=0.0)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageshow(6,model,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageshow(6,model,\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageshow(6,model,\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
